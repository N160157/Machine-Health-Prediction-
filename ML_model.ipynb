{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the numeric-labeled dataset\n",
    "df = pd.read_csv(\"combined_labeled_data_numeric.csv\")\n",
    "\n",
    "# Features and labels\n",
    "X = df[[\"col1\", \"col2\", \"col3\"]]  # independent variables\n",
    "y = df[\"label\"]                  # target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "Accuracy: 0.8488699214749061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     44208\n",
      "           1       0.85      1.00      0.92    248692\n",
      "\n",
      "    accuracy                           0.85    292900\n",
      "   macro avg       0.42      0.50      0.46    292900\n",
      "weighted avg       0.72      0.85      0.78    292900\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Accuracy: 0.8447900307272107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.36      0.41     44208\n",
      "           1       0.89      0.93      0.91    248692\n",
      "\n",
      "    accuracy                           0.84    292900\n",
      "   macro avg       0.69      0.64      0.66    292900\n",
      "weighted avg       0.83      0.84      0.84    292900\n",
      "\n",
      "\n",
      "Linear SVM\n",
      "Accuracy: 0.8490679412768863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     44208\n",
      "           1       0.85      1.00      0.92    248692\n",
      "\n",
      "    accuracy                           0.85    292900\n",
      "   macro avg       0.42      0.50      0.46    292900\n",
      "weighted avg       0.72      0.85      0.78    292900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/home/kpnaveen/miniconda3/envs/nstocks/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data1/home/kpnaveen/miniconda3/envs/nstocks/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data1/home/kpnaveen/miniconda3/envs/nstocks/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Linear SVM\": LinearSVC(max_iter=10000),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"XGBoost\": XGBClassifier()\n",
    "}\n",
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example new datapoint\n",
    "new_data = [[2879, 2971, 2879]]  # Format: [[col1, col2, col3]]\n",
    "prediction = model.predict(new_data)\n",
    "print(\"Predicted label:\", prediction[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nstocks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
